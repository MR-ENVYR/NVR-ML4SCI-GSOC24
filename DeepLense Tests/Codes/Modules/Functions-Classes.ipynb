{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d3d04d-b9c8-4aa3-a130-ec15e2fa4376",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e928b4-8192-4f75-88f2-87a152bbad06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74af43f-ece6-44d1-8c31-d68557aab5dc",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951093c-ca58-4ab0-a97a-fe92998fcdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helpers\n",
    "def random_plots(dataset):\n",
    "    fig, axs = plt.subplots(2, 5, layout=\"tight\", figsize=(15, 10))\n",
    "    for i in range(axs.shape[1]):\n",
    "        idx = np.random.randint(dataset.__len__())\n",
    "        img, label = dataset.__getitem__(idx)\n",
    "        ax0, ax1 = axs[:, i]\n",
    "        ax0.imshow(img.squeeze(), cmap=\"gray\")\n",
    "        ax0.set_title(f\"Label: {label}\")\n",
    "        ax1.plot(img.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6986ff8-675d-434a-a109-4597137a14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model trainers and testers\n",
    "def modeltrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    trainloader: DataLoader,\n",
    "    valloader: DataLoader = None,\n",
    "    epochs: int = 5,\n",
    "    criterion=nn.MSELoss(),\n",
    "    scheduler=None,\n",
    "    meta: bool = False,\n",
    "    pre_trained_models: dict = None,\n",
    "    meta_pred_func=None,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Returns a tuple of trained model and loss lists. Can also train meta models.\n",
    "    Parameters:\n",
    "        model (PyTorch Model): An instance of a PyTorch model\n",
    "        optimizer (nn.optim): An instance of an optimizer linked to the model's parameters\n",
    "        trainloader (DataLoader): Train dataloader to be used while training\n",
    "        valloader (DataLoader, optional, None): Validation loader to be used for validation and early stopping\n",
    "        epochs (int, recommended, 5): No. of epochs to be trained for\n",
    "        criterion (optional, nn.MSELoss()): Loss function to be used for backprop\n",
    "        scheduler (optional, None): Learning rate scheduler to be used if needed\n",
    "        meta (bool, optional, False): Whether the model to be trained is a meta model\n",
    "        pre_trained_models (dict, optional, None): Pre-trained models whose outputs are to be used in meta training\n",
    "        meta_pred_func (function, optional, None): Function which uses outputs of pre-trained models and meta model to provide a new output\n",
    "    Returns:\n",
    "        model: Trained PyTorch model\n",
    "        train_loss: Training loss of each epoch\n",
    "        val_loss: Validation loss of each epoch\n",
    "    \"\"\"\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    # Establishing valid meta parameters for meta mode\n",
    "    if meta is True:\n",
    "        assert pre_trained_models is not None, \"Provide pre_trained_models!\"\n",
    "        assert meta_pred_func is not None, \"Provide meta_pred_func!\"\n",
    "\n",
    "    # Using GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        devname = \"cuda\"\n",
    "    else:\n",
    "        devname = \"cpu\"\n",
    "    device = torch.device(devname)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.to(device)\n",
    "        model.train()  # prep model for training\n",
    "        pbar = tqdm(total=len(trainloader), leave=True)\n",
    "        epoch_loss = 0\n",
    "        epoch_start = time.time()\n",
    "        for batch, (features, target) in enumerate(trainloader):\n",
    "            features, target = features.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if meta is True:\n",
    "                weights = model(features)\n",
    "                pred = meta_pred_func(\n",
    "                    pre_trained_models=pre_trained_models, X=features, weights=weights\n",
    "                )\n",
    "            else:\n",
    "                pred = model(features)\n",
    "            loss = criterion(pred.to(device), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.cpu().data.item()\n",
    "            pbar.update()\n",
    "            pbar.desc = f\"Train loss: {loss.cpu().data.item()} | EP({epoch})\"\n",
    "        train_loss.append(epoch_loss / len(trainloader))\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        epoch_loss = 0\n",
    "        epoch_end = time.time()\n",
    "        epoch_time = time.strftime(\"%H:%M:%S\", time.gmtime(epoch_end - epoch_start))\n",
    "        print(f\"Epoch finished in {epoch_time}\")\n",
    "\n",
    "        if (valloader is not None) and (len(valloader) > 1):\n",
    "            with torch.no_grad():\n",
    "                for batch, (features, target) in enumerate(valloader):\n",
    "                    features, target = features.to(device), target.to(device)\n",
    "                    if meta is True:\n",
    "                        weights = model(features)\n",
    "                        pred = meta_pred_func(\n",
    "                            pre_trained_models=pre_trained_models,\n",
    "                            X=features,\n",
    "                            weights=weights,\n",
    "                        )\n",
    "                    else:\n",
    "                        pred = model(features)\n",
    "                    loss = criterion(pred, target)\n",
    "                    epoch_loss += loss.cpu().data.item()\n",
    "            val_loss.append(epoch_loss / len(valloader))\n",
    "        pbar.refresh()\n",
    "        pbar.close()\n",
    "    return model, train_loss, val_loss\n",
    "\n",
    "\n",
    "# Optim Func - Change optimizer here if required\n",
    "def optim(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    return torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584ff38-4123-42ee-a8eb-624553c49911",
   "metadata": {},
   "source": [
    "# DataLoaders and Datasets for loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f58a1-a490-4ee0-be8c-1e76bd32f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CT1Set(Dataset):\n",
    "    \"\"\"Creates a PyTorch Image Dataset given a set of file paths and label mapping\"\"\"\n",
    "\n",
    "    def __init__(self, file_paths, label_map, transform=None, target_transform=None):\n",
    "        self.files = file_paths\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "        self.target_transform = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.files[idx]\n",
    "        image = np.load(file)\n",
    "        label = self.label_map[file.parent.name]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7ad8e-8519-4e43-b4dc-dbc18cf6d898",
   "metadata": {},
   "source": [
    "# Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2ffee-8c88-4fbf-9ac7-6b4647c2e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Generator\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"Creates a CNN based on specificatioins\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_size: int,\n",
    "        n_convs: int,\n",
    "        n_lin: int,\n",
    "        hid_size: int,\n",
    "        out_size: int,\n",
    "        batnorm: bool = False,\n",
    "        c_start: int = 1,\n",
    "        increasing: bool = False,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        padding: int = 0,\n",
    "        activation=nn.LeakyReLU(),\n",
    "        last_activation=nn.LeakyReLU(),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the CNN with the given parameters.\n",
    "        Parameters:\n",
    "            inp_size (int): Number of features given as input to the model. Must be at least 1\n",
    "            n_convs (int): Number of convolutional layers to use in the model. Must be at least 1\n",
    "            n_lin (int): Number of hidden layers to use in the model. Must be at least 1.\n",
    "            hid_size (int): Number of neurons in each hidden layer. Must be at least 1\n",
    "            out_size (int): Number of variables to be predicted. Must be at least 1\n",
    "            batnorm (bool, optional, False): Whether to use batch normalization\n",
    "            c_start (int, optional, 1): Controls channels in the layers. 4**i for i in range(c_start, c_start+n_convs)\n",
    "            increasing (bool, optional, True): Whether convolutional depth must keep increasing or be pyramidal\n",
    "            kernel_size (int, optional, 3): Kernel size for each convolutional layer\n",
    "            stride (int, optional, 1): Stride for kernel in each convolutional layer\n",
    "            padding (int, optional, 0): Padding in each convolutional layer\n",
    "            activation: Activation function to use in between linear layers. Must be from nn module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if any(\n",
    "            [\n",
    "                inp_size < 1,\n",
    "                n_convs < 1,\n",
    "                n_lin < 1,\n",
    "                hid_size < 1,\n",
    "                out_size < 1,\n",
    "                c_start < 1,\n",
    "                kernel_size < 1,\n",
    "                stride < 1,\n",
    "            ]\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Please enter a value greater than or equal to 1 for all the integer parameters!\"\n",
    "            )\n",
    "\n",
    "        # Convolutional Calcs\n",
    "        # clayers = [4**i for i in range(c_start, c_start + n_convs + 1)]\n",
    "        # clayers.insert(0, 1)\n",
    "        self.inp_size = inp_size\n",
    "        clayers = [4**i for i in range(n_convs)]\n",
    "\n",
    "        if increasing:\n",
    "            clayers = clayers\n",
    "        else:\n",
    "            if n_convs % 2 == 0:\n",
    "                clayers += reversed(clayers)\n",
    "            else:\n",
    "                clayers += reversed(clayers[:-1])\n",
    "\n",
    "        # Conv part generation\n",
    "        conv_part = []\n",
    "        for i in range(1, len(clayers)):\n",
    "            if batnorm is True:\n",
    "                layer = [\n",
    "                    nn.Conv2d(\n",
    "                        clayers[i - 1],\n",
    "                        clayers[i],\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(clayers[i]),\n",
    "                    activation,\n",
    "                ]\n",
    "            else:\n",
    "                layer = [\n",
    "                    nn.Conv2d(\n",
    "                        clayers[i - 1],\n",
    "                        clayers[i],\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding,\n",
    "                    ),\n",
    "                    activation,\n",
    "                ]\n",
    "            conv_part.extend(layer)\n",
    "        self.cnn = nn.Sequential(*conv_part)\n",
    "\n",
    "        # First hid calculations\n",
    "        # conv_outs = [inp_size]\n",
    "        # for i in range(n_convs + 1):\n",
    "        #     Li = conv_outs[-1]\n",
    "        #     Lo = ((Li + 2 * padding - kernel_size) / stride) + 1\n",
    "        #     if int(Lo) != Lo:\n",
    "        #         raise ValueError(\n",
    "        #             \"Please check stride, kernel_size and padding to ensure sizes are returned as int!\"\n",
    "        #         )\n",
    "        #     else:\n",
    "        #         conv_outs.append(int(Lo))\n",
    "        # conv_out = conv_outs[-1]\n",
    "        conv_out = self._calc_first_hid()\n",
    "\n",
    "        # Linear part generation (MLP)\n",
    "        lin_part = (\n",
    "            [nn.Linear(conv_out, hid_size), activation]\n",
    "            + [nn.Linear(hid_size, hid_size), activation] * n_lin\n",
    "            + [nn.Linear(hid_size, out_size), last_activation]\n",
    "        )\n",
    "\n",
    "        # model = conv_part + lin_part\n",
    "        self.mlp = nn.Sequential(*lin_part)\n",
    "\n",
    "    def _calc_first_hid(self):\n",
    "        dummy = torch.randn(32, self.inp_size)\n",
    "        dummy = self.cnn(dummy.unsqueeze(1))  # .unsqueeze(1)\n",
    "        first_hid = dummy.flatten(1).shape[1]\n",
    "        # print(first_hid)\n",
    "        return first_hid\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward passes the input tensor\"\"\"\n",
    "        # x = torch.permute(x, (1, 0))\n",
    "        x = x.unsqueeze(1)\n",
    "        cnn_out = self.cnn(x).flatten(1)\n",
    "        output = self.mlp(cnn_out).squeeze()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe16bb-cd24-48da-9db6-830ca1336b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
