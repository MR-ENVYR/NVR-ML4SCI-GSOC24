{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d3d04d-b9c8-4aa3-a130-ec15e2fa4376",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e928b4-8192-4f75-88f2-87a152bbad06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74af43f-ece6-44d1-8c31-d68557aab5dc",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951093c-ca58-4ab0-a97a-fe92998fcdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helpers\n",
    "def random_plots(dataset):\n",
    "    fig, axs = plt.subplots(2, 5, layout=\"tight\", figsize=(15, 10))\n",
    "    for i in range(axs.shape[1]):\n",
    "        idx = np.random.randint(dataset.__len__())\n",
    "        img, label = dataset.__getitem__(idx)\n",
    "        label = torch.argmax(label).item()\n",
    "        ax0, ax1 = axs[:, i]\n",
    "        ax0.imshow(img.squeeze(), cmap=\"gray\")\n",
    "        ax0.set_title(f\"Label: {label}\")\n",
    "        ax1.plot(img.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6986ff8-675d-434a-a109-4597137a14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model trainers and testers\n",
    "def modeltrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    trainloader: DataLoader,\n",
    "    valloader: DataLoader = None,\n",
    "    epochs: int = 5,\n",
    "    criterion=nn.MSELoss(),\n",
    "    scheduler=None,\n",
    "    meta: bool = False,\n",
    "    pre_trained_models: dict = None,\n",
    "    meta_pred_func=None,\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Returns a tuple of trained model and loss lists. Can also train meta models.\n",
    "    Parameters:\n",
    "        model (PyTorch Model): An instance of a PyTorch model\n",
    "        optimizer (nn.optim): An instance of an optimizer linked to the model's parameters\n",
    "        trainloader (DataLoader): Train dataloader to be used while training\n",
    "        valloader (DataLoader, optional, None): Validation loader to be used for validation and early stopping\n",
    "        epochs (int, recommended, 5): No. of epochs to be trained for\n",
    "        criterion (optional, nn.MSELoss()): Loss function to be used for backprop\n",
    "        scheduler (optional, None): Learning rate scheduler to be used if needed\n",
    "        meta (bool, optional, False): Whether the model to be trained is a meta model\n",
    "        pre_trained_models (dict, optional, None): Pre-trained models whose outputs are to be used in meta training\n",
    "        meta_pred_func (function, optional, None): Function which uses outputs of pre-trained models and meta model to provide a new output\n",
    "    Returns:\n",
    "        model: Trained PyTorch model\n",
    "        train_loss: Training loss of each epoch\n",
    "        val_loss: Validation loss of each epoch\n",
    "    \"\"\"\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    # Establishing valid meta parameters for meta mode\n",
    "    if meta is True:\n",
    "        assert pre_trained_models is not None, \"Provide pre_trained_models!\"\n",
    "        assert meta_pred_func is not None, \"Provide meta_pred_func!\"\n",
    "\n",
    "    # Using GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        devname = \"cuda\"\n",
    "    else:\n",
    "        devname = \"cpu\"\n",
    "    device = torch.device(devname)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.to(device)\n",
    "        model.train()  # prep model for training\n",
    "        pbar = tqdm(total=len(trainloader), leave=True)\n",
    "        epoch_loss = 0\n",
    "        epoch_start = time.time()\n",
    "        for batch, (features, target) in enumerate(trainloader):\n",
    "            features, target = features.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if meta is True:\n",
    "                weights = model(features)\n",
    "                pred = meta_pred_func(\n",
    "                    pre_trained_models=pre_trained_models, X=features, weights=weights\n",
    "                )\n",
    "            else:\n",
    "                pred = model(features)\n",
    "            loss = criterion(pred.to(device), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.cpu().data.item()\n",
    "            pbar.update()\n",
    "            pbar.desc = f\"Train loss: {loss.cpu().data.item()} | EP({epoch})\"\n",
    "        train_loss.append(epoch_loss / len(trainloader))\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        epoch_loss = 0\n",
    "        epoch_end = time.time()\n",
    "        epoch_time = time.strftime(\"%H:%M:%S\", time.gmtime(epoch_end - epoch_start))\n",
    "        print(f\"Epoch finished in {epoch_time}\")\n",
    "\n",
    "        if (valloader is not None) and (len(valloader) > 1):\n",
    "            with torch.no_grad():\n",
    "                for batch, (features, target) in enumerate(valloader):\n",
    "                    features, target = features.to(device), target.to(device)\n",
    "                    if meta is True:\n",
    "                        weights = model(features)\n",
    "                        pred = meta_pred_func(\n",
    "                            pre_trained_models=pre_trained_models,\n",
    "                            X=features,\n",
    "                            weights=weights,\n",
    "                        )\n",
    "                    else:\n",
    "                        pred = model(features)\n",
    "                    loss = criterion(pred, target)\n",
    "                    epoch_loss += loss.cpu().data.item()\n",
    "            val_loss.append(epoch_loss / len(valloader))\n",
    "        pbar.refresh()\n",
    "        pbar.close()\n",
    "    return model, train_loss, val_loss\n",
    "\n",
    "\n",
    "# Optim Func - Change optimizer here if required\n",
    "def optim(model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    return torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Multi-class ROC Curve\n",
    "def mult_ROC(y_test_ohe, y_probs):\n",
    "    '''Plots ROC for multi-class classification'''\n",
    "    n_classes = y_test_ohe.shape[1]\n",
    "    fpr, tpr, roc_auc = [[0] * n_classes]*3\n",
    "    fig, axs = plt.subplots(1, 3, layout=\"tight\")\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_ohe[:, i], y_probs[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        ax = axs[i]\n",
    "        ax.plot(fpr, tpr)\n",
    "        ax.set_title(f\"ROC Curve for Class {i}\")\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "\n",
    "    # fpr_grid = np.linspace(0, 1, 1000)\n",
    "    # mean_tpr = np.zeros_like(fpr_grid)\n",
    "    # mean_tpr = sum(map(lambda x: np.interp(fpr_grid, x[0], x[1]), zip(fpr, tpr))) / n_classes\n",
    "    # fpr_macro = fpr_grid\n",
    "    # tpr_macro = mean_tpr\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.plot(fpr_macro, tpr_macro)\n",
    "    return fig, axs\n",
    "\n",
    "# Model tester\n",
    "def metrictester(\n",
    "    pt_trained: dict,\n",
    "    metric_dict: dict,\n",
    "    ROC_AUC: bool,\n",
    "    testloader,\n",
    "    multi_class: bool = True,\n",
    "    last_activation=None,\n",
    "    save_metrics: bool = False,\n",
    "    save_path=None,\n",
    "    save_name: str = None,\n",
    "    meta: bool = False,\n",
    "    pre_trained_models: dict = None,\n",
    "    meta_pred_func=None,\n",
    "    log_scale=False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Scores both trained PyTorch and Scikit-Learn models using provided metrics and data.\n",
    "    Parameters:\n",
    "        pt_trained (dict): A dictionary of trained PyTorch Models. Should be meta-models if meta is True\n",
    "        metric_dict (dict): Dictionary of metrics\n",
    "        ROC_AUC (bool): Whether to computer ROC curve and AUC_ROC score\n",
    "        testloader (DataLoader): Test data loader (PyTorch compatible)\n",
    "        multi_class (bool, optional, True): Whether it is multi_class classification\n",
    "        last_activation (optional, None): Activation for last layer in case training was done with PyTorch cross entropy loss\n",
    "        save_metrics (bool, optional, False): Whether to save metrics (csv)\n",
    "        save_path (Pathlike, optional, None): Path to folder where metrics should be saved\n",
    "        save_name (str, optional, None): Additional string to add in file name\n",
    "        batch_size (int, optional, 64): Batch Size to be used in DataLoaders\n",
    "        meta (bool, optional, False): Whether the model to be trained is a meta model\n",
    "        pre_trained_models (dict, optional, None): Pre-trained models whose outputs are to be used in meta training\n",
    "        meta_pred_func (function, optional, None): Function which uses outputs of pre-trained models and meta model to provide a new output\n",
    "        log_scale (bool, optional, False): Whether log scale was used during scaling\n",
    "    Returns:\n",
    "        score_dict: Dictionary containing metrics for each model\n",
    "        pred_dict: Dictionary containing predictions of each model\n",
    "    \"\"\"\n",
    "    # Establishing models are available\n",
    "    assert (\n",
    "        pt_trained is not None\n",
    "    ), \"Please provide sklearn or PyTorch models for prediction\"\n",
    "\n",
    "    # Establishing valid meta parameters for meta mode\n",
    "    if meta is True:\n",
    "        assert pre_trained_models is not None\n",
    "        assert meta_pred_func is not None\n",
    "\n",
    "    # Defining dictionaries to store predictions and keys\n",
    "    # pred_dict = {}  # {key: [] for key in sk_trained.keys()}\n",
    "    # pred_prob_dict = {}\n",
    "    pred_dict = {key: [] for key in pt_trained.keys()}\n",
    "    pred_prob_dict = {key: [] for key in pt_trained.keys()}\n",
    "    score_dict = {}\n",
    "\n",
    "    # Defining DataLoader for PyTorch models\n",
    "    # testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Pt predictions\n",
    "    # Using GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        devname = \"cuda\"\n",
    "    else:\n",
    "        devname = \"cpu\"\n",
    "    device = torch.device(devname)\n",
    "    y_test = []\n",
    "    if pt_trained is not None:\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(total=len(testloader), leave=True)\n",
    "            for batch, (features, target) in enumerate(testloader):\n",
    "                y_test.append(target)\n",
    "                features, target = features.to(device), target.to(device)\n",
    "                for name, model in pt_trained.items():\n",
    "                    model = model[0]\n",
    "                    model.to(device)\n",
    "                    model.eval()\n",
    "                    if meta is True:\n",
    "                        weights = model(features)\n",
    "                        pred = meta_pred_func(\n",
    "                            pre_trained_models=pre_trained_models,\n",
    "                            X=features,\n",
    "                            weights=weights,\n",
    "                        )\n",
    "                    else:\n",
    "                        pred = model(features)\n",
    "                        if multi_class is True:\n",
    "                            pred = last_activation(pred) if last_activation else pred\n",
    "                            # pred = torch.argmax(pred).reshape(1)\n",
    "                            pred_dict[name].append(pred.cpu())\n",
    "                            # pred_prob_dict[name].append(pred.cpu())\n",
    "                        else:\n",
    "                            pred_dict[name].append(pred.cpu())\n",
    "\n",
    "                pbar.update()\n",
    "                pbar.desc = f\"Batch: {batch} | Model: {name}\"\n",
    "            pbar.refresh()\n",
    "            pbar.close()\n",
    "        pred_prob_dict = {k: torch.cat(v).numpy() for k, v in pred_dict.items()}\n",
    "        pred_dict = {k: torch.argmax(torch.cat(v), axis=1).numpy() for k, v in pred_dict.items()}\n",
    "\n",
    "    # Metric calculations\n",
    "    y_test = torch.cat(y_test).numpy()\n",
    "    y_labels = np.argmax(y_test, axis=1)\n",
    "    metric_funcs = metric_dict.values()\n",
    "    metric_names = metric_dict.keys()\n",
    "    for name, preds in pred_dict.items():\n",
    "        scores = list(map(lambda x: x(y_labels, preds), metric_funcs))\n",
    "        score_dict[name] = dict(zip(metric_names, scores))\n",
    "        if ROC_AUC is True:\n",
    "            probs = pred_prob_dict[name]\n",
    "            auc = roc_auc_score(y_labels, probs, multi_class='ovr') if multi_class else roc_auc(y_test, probs, multi_class='ovr')\n",
    "            fig, axs = mult_ROC(y_test, probs)\n",
    "            # ax.set_title(f\"ROC Curve of model - {name}\")\n",
    "            # ax.xlabel(\"False Positive Rate\")\n",
    "            # ax.ylabel(\"True Positive Rate\")\n",
    "            score_dict[name][\"AUC_ROC\"] = auc\n",
    "            score_dict[name][\"ROC_Curve\"] = (fig, axs)\n",
    "\n",
    "    if save_metrics is True:\n",
    "        try:\n",
    "            score_df = pd.DataFrame(score_dict).T\n",
    "            now = datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "            name = (\n",
    "                f\"metrics_{now}.csv\"\n",
    "                if save_name is None\n",
    "                else f\"metrics_{save_name}_{now}.csv\"\n",
    "            )\n",
    "            save_path = Path(save_path) / name if save_path else Path(name)\n",
    "            score_df.to_csv(save_path)\n",
    "            print(f\"Metrics saved to {save_path}!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fatal Error: Metric saving failed with exception {e}\")\n",
    "\n",
    "    # Flattening arrays in pred_dict for single output case\n",
    "    for name, preds in pred_dict.items():\n",
    "        if (len(preds.shape) > 1) and (preds.shape[1] < 2):\n",
    "            pred_dict[name] = preds.ravel()\n",
    "        else:\n",
    "            continue\n",
    "    # pred_dict = {name: preds.rav/el() if preds.shape[1] < 2 else preds for name, preds in pred_dict.items()}\n",
    "    return score_dict, pred_dict, pred_prob_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584ff38-4123-42ee-a8eb-624553c49911",
   "metadata": {},
   "source": [
    "# DataLoaders and Datasets for loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f58a1-a490-4ee0-be8c-1e76bd32f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CT1Set(Dataset):\n",
    "    \"\"\"Creates a PyTorch Image Dataset given a set of file paths and label mapping\"\"\"\n",
    "\n",
    "    def __init__(self, file_paths, label_map, transform=None, target_transform=None):\n",
    "        self.files = file_paths\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "        self.target_transform = None\n",
    "        self.num_labels = len(self.label_map)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.files[idx]\n",
    "        image = torch.tensor(np.load(file))\n",
    "        label = self.label_map[file.parent.name]\n",
    "\n",
    "        # One hot encoding for labels\n",
    "        label_ohe = torch.zeros(self.num_labels)\n",
    "        label_ohe[label] = 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label_ohe  # label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7ad8e-8519-4e43-b4dc-dbc18cf6d898",
   "metadata": {},
   "source": [
    "# Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2ffee-8c88-4fbf-9ac7-6b4647c2e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Generator\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"Creates a CNN based on specificatioins\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_size: int,\n",
    "        n_convs: int,\n",
    "        n_lin: int,\n",
    "        hid_size: int,\n",
    "        out_size: int,\n",
    "        batnorm: bool = False,\n",
    "        c_start: int = 1,\n",
    "        increasing: bool = False,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        padding: int = 0,\n",
    "        activation=nn.LeakyReLU(),\n",
    "        last_activation=nn.LeakyReLU(),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the CNN with the given parameters.\n",
    "        Parameters:\n",
    "            inp_size (int): Number of features given as input to the model. Must be at least 1\n",
    "            n_convs (int): Number of convolutional layers to use in the model. Must be at least 1\n",
    "            n_lin (int): Number of hidden layers to use in the model. Must be at least 1.\n",
    "            hid_size (int): Number of neurons in each hidden layer. Must be at least 1\n",
    "            out_size (int): Number of variables to be predicted. Must be at least 1\n",
    "            batnorm (bool, optional, False): Whether to use batch normalization\n",
    "            c_start (int, optional, 1): Controls channels in the layers. 4**i for i in range(c_start, c_start+n_convs)\n",
    "            increasing (bool, optional, True): Whether convolutional depth must keep increasing or be pyramidal\n",
    "            kernel_size (int, optional, 3): Kernel size for each convolutional layer\n",
    "            stride (int, optional, 1): Stride for kernel in each convolutional layer\n",
    "            padding (int, optional, 0): Padding in each convolutional layer\n",
    "            activation: Activation function to use in between linear layers. Must be from nn module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if any(\n",
    "            [\n",
    "                inp_size < 1,\n",
    "                n_convs < 1,\n",
    "                n_lin < 1,\n",
    "                hid_size < 1,\n",
    "                out_size < 1,\n",
    "                c_start < 1,\n",
    "                kernel_size < 1,\n",
    "                stride < 1,\n",
    "            ]\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Please enter a value greater than or equal to 1 for all the integer parameters!\"\n",
    "            )\n",
    "\n",
    "        # Convolutional Calcs\n",
    "        # clayers = [4**i for i in range(c_start, c_start + n_convs + 1)]\n",
    "        # clayers.insert(0, 1)\n",
    "        self.inp_size = inp_size\n",
    "        clayers = [4**i for i in range(n_convs)]\n",
    "\n",
    "        if increasing:\n",
    "            clayers = clayers\n",
    "        else:\n",
    "            if n_convs % 2 == 0:\n",
    "                clayers += reversed(clayers)\n",
    "            else:\n",
    "                clayers += reversed(clayers[:-1])\n",
    "\n",
    "        # Conv part generation\n",
    "        conv_part = []\n",
    "        for i in range(1, len(clayers)):\n",
    "            if batnorm is True:\n",
    "                layer = [\n",
    "                    nn.Conv2d(\n",
    "                        clayers[i - 1],\n",
    "                        clayers[i],\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(clayers[i]),\n",
    "                    activation,\n",
    "                ]\n",
    "            else:\n",
    "                layer = [\n",
    "                    nn.Conv2d(\n",
    "                        clayers[i - 1],\n",
    "                        clayers[i],\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding,\n",
    "                    ),\n",
    "                    activation,\n",
    "                ]\n",
    "            conv_part.extend(layer)\n",
    "        self.cnn = nn.Sequential(*conv_part)\n",
    "\n",
    "        # First hid calculations\n",
    "        # conv_outs = [inp_size]\n",
    "        # for i in range(n_convs + 1):\n",
    "        #     Li = conv_outs[-1]\n",
    "        #     Lo = ((Li + 2 * padding - kernel_size) / stride) + 1\n",
    "        #     if int(Lo) != Lo:\n",
    "        #         raise ValueError(\n",
    "        #             \"Please check stride, kernel_size and padding to ensure sizes are returned as int!\"\n",
    "        #         )\n",
    "        #     else:\n",
    "        #         conv_outs.append(int(Lo))\n",
    "        # conv_out = conv_outs[-1]\n",
    "        conv_out = self._calc_first_hid()\n",
    "\n",
    "        # Linear part generation (MLP)\n",
    "        lin_part = (\n",
    "            [nn.Linear(conv_out, hid_size), activation]\n",
    "            + [nn.Linear(hid_size, hid_size), activation] * n_lin\n",
    "            + [nn.Linear(hid_size, out_size), last_activation]\n",
    "        )\n",
    "\n",
    "        # model = conv_part + lin_part\n",
    "        self.mlp = nn.Sequential(*lin_part)\n",
    "\n",
    "    def _calc_first_hid(self):\n",
    "        dummy = torch.randn(32, self.inp_size)\n",
    "        dummy = self.cnn(dummy.unsqueeze(1))  # .unsqueeze(1)\n",
    "        first_hid = dummy.flatten(1).shape[1]\n",
    "        # print(first_hid)\n",
    "        return first_hid\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward passes the input tensor\"\"\"\n",
    "        # x = torch.permute(x, (1, 0))\n",
    "        x = x.unsqueeze(1)\n",
    "        cnn_out = self.cnn(x).flatten(1)\n",
    "        output = self.mlp(cnn_out).squeeze()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe16bb-cd24-48da-9db6-830ca1336b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
